{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "9q8Pj2FFiM4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892edcc4-9af8-4be5-e292-25bf09beb1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Modules"
      ],
      "metadata": {
        "id": "3PyHgLcriSmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gensim"
      ],
      "metadata": {
        "id": "g-1Nw3x9EujH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01788607-4a58-49ff-e580-0a6566e92f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT4rg7yAhzrX"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Model\n",
        "import re\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "l1eWVRT3l_4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set\n",
        "inp = np.load('/content/drive/MyDrive/Clickbait/MultiModal/Inputs.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "W7J0_flhmbJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W2V Embedding"
      ],
      "metadata": {
        "id": "5JA_pBdrIp9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the word2vec model\n",
        "w2v_model = gensim.models.Word2Vec(inp[:,1],\n",
        "                                   vector_size=100,\n",
        "                                   window=5,\n",
        "                                   min_count=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUTsweCaIven",
        "outputId": "bbbe7c14-f2ab-4924-b9e2-52e5042f1fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = set(w2v_model.wv.index_to_key )\n",
        "X_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in inp[:,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlzGM4qbI3VY",
        "outputId": "7e23f4f6-2ac3-482e-e53c-2e70539c7020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6d8a89087f60>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_vect_avg = []\n",
        "for v in X_vect:\n",
        "    if v.size:\n",
        "        X_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "id": "qN_dEweAI8y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the Input array with vector representations and reshaping them to fit the trained models\n",
        "for i in range(0, len(X_vect_avg)):\n",
        "  inp[i][1] = np.reshape(np.array(X_vect_avg[i]), (1,1,100))\n",
        "  inp[i][0] = np.reshape(inp[i][0], (1, 126, 126))"
      ],
      "metadata": {
        "id": "dSpoXD6dQaXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Modal Model"
      ],
      "metadata": {
        "id": "bFr_pfr5vNp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weighted Output Function"
      ],
      "metadata": {
        "id": "medsydZOv5iW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of the models are as follows:\n",
        "\n",
        "- Text Classifier (Bi-GRU with Word2Vec) = 0.789\n",
        "\n",
        "- Image Classifier (2-layer CNN) = 0.86\n"
      ],
      "metadata": {
        "id": "OHzXMaoHAsmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Accuracy = Image Accuracy + Text Accuracy\n",
        "\n",
        "Image Weights = Image_Accuracy/Total Accuracy\n",
        "\n",
        "Text Weights = Text_Accuracy/Total Accuracy\n",
        "\n",
        "Total Accuracy = 1(Total Image Accuracy) + 1(Total Text Accuracy) = 2"
      ],
      "metadata": {
        "id": "rx_0h37jCayu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_output(img, text):\n",
        "  total_acc = float(2)\n",
        "  img_wgts = float(0.789/2)\n",
        "  txt_wgts = float(0.86/2)\n",
        "  op = img_wgts * img + txt_wgts * text\n",
        "  if op > 0.5:\n",
        "    return \"Clickbait\"\n",
        "  else:\n",
        "    return \"Not Clickbait\""
      ],
      "metadata": {
        "id": "-8KyAdzSv8S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input to the multi modal model must of the following form:\n",
        "\n",
        "[Image, Text]"
      ],
      "metadata": {
        "id": "afO2EajQve61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_classifier = tf.keras.models.load_model('/content/drive/MyDrive/Clickbait/Text_Dataset/weights/model_BiGRU_w2v') # Text Classifier\n",
        "image_classifier = tf.keras.models.load_model('/content/drive/MyDrive/Clickbait/Image_Models/CNN') # Image Classifier"
      ],
      "metadata": {
        "id": "q82gHIbNbIIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the Multimodal Architecture by Combining the different best performing models\n",
        "def multi_modal_model(X):\n",
        "  results = []\n",
        "  for i in X:\n",
        "    if len(list(X))==1:\n",
        "      r = text_classifier(i)\n",
        "      if r > 0.5:\n",
        "        results.append(\"Clickbait\")\n",
        "      else:\n",
        "        results.append(\"Not Clickbait\")\n",
        "    else:\n",
        "      results.append(weighted_output(image_classifier.predict(i[0]), text_classifier.predict(i[1])))\n",
        "  return results"
      ],
      "metadata": {
        "id": "Sj2H3P4OtVdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = multi_modal_model(inp)"
      ],
      "metadata": {
        "id": "eMYUzrw2a2si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77695e67-6e88-4a0b-b483-9f495c543b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X9YP-DgYTyF",
        "outputId": "ac8e9303-06f1-4c04-f513-a59a50ee7e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Not Clickbait',\n",
              " 'Not Clickbait',\n",
              " 'Not Clickbait',\n",
              " 'Not Clickbait',\n",
              " 'Not Clickbait']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFl_-GiDYVnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}